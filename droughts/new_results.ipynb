{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb0fe22",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "790fcb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#sys.path.append(\"/Users/paolo/Documents/methods/CMI_FS\")\n",
    "#from feature_selection import forwardFeatureSelection\n",
    "\n",
    "sys.path.append(\"../LinCFA\")\n",
    "from LinCFA import LinCFA\n",
    "\n",
    "sys.path.append(\"../NonLinCFA\")\n",
    "from NonLinCFA import NonLinCFA\n",
    "\n",
    "sys.path.append(\"../GenLinCFA\")\n",
    "from GenLinCFA import GenLinCFA\n",
    "\n",
    "sys.path.append(\"../droughts\")\n",
    "from aux import prepare_target,prepare_features,compare_methods\n",
    "\n",
    "#from aux import standardize,unfold_dataset,compute_r2,prepare_target,prepare_features,aggregate_unfolded_data,aggregate_unfolded_data_onlyTrain,FS_with_linearWrapper,compare_methods, compute_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d2b30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('droughts_extended.csv')\n",
    "df_trainVal_withTar = df.iloc[:-392,:]\n",
    "df_test_withTar = df.iloc[-392:,:]\n",
    "df_trainVal = df.iloc[:-392,:-1]\n",
    "df_test = df.iloc[-392:,:-1]\n",
    "target_df_trainVal = df.iloc[:-392,-1]\n",
    "target_df_test = df.iloc[-392:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ede5c",
   "metadata": {},
   "source": [
    "# NonLinCFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b749ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: 0,0.001\n"
     ]
    }
   ],
   "source": [
    "for eps in [0.001,0.0001,0.00001,0.000001]:\n",
    "    for curr_seed in [0,1,2,3,4]:\n",
    "        curr_df_trainVal = df_trainVal[np.random.default_rng(seed=curr_seed).permutation(df_trainVal.columns.values)]\n",
    "        curr_df_test = df_test[np.random.default_rng(seed=curr_seed).permutation(df_test.columns.values)]\n",
    "        curr_df_trainVal_withTar = pd.concat((curr_df_trainVal,target_df_trainVal), axis=1)\n",
    "        \n",
    "        print(f'Started: {curr_seed},{eps}')\n",
    "        output = NonLinCFA(curr_df_trainVal_withTar,'mean_std', eps, -5 , 0).compute_clusters()\n",
    "        \n",
    "        aggregate_trainVal = pd.DataFrame()\n",
    "        aggregate_test = pd.DataFrame()\n",
    "        for i in range(len(output)):\n",
    "            aggregate_trainVal[str(i)] = curr_df_trainVal_withTar[output[i]].mean(axis=1)\n",
    "            aggregate_trainVal = aggregate_trainVal.copy()\n",
    "            aggregate_test[str(i)] = curr_df_test[output[i]].mean(axis=1)\n",
    "            aggregate_test = aggregate_test.copy()\n",
    "        print(f'Number of aggregated features: {len(output)}\\n')\n",
    "        compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, list(aggregate_trainVal.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a5fb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "1\n",
      "1\n",
      "964\n",
      "23\n",
      "85\n",
      "1\n",
      "1\n",
      "423\n",
      "251\n",
      "184\n",
      "28\n",
      "17\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "output = NonLinCFA(train_df_withTar,'mean_std', 0.001, -5 , 0).compute_clusters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f3223e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of aggregated features: 16\n",
      "\n",
      "Full aggregate regression train score: 0.9087537707401862, test score: 0.9508483364063816\n",
      "Aggregate regression train score with FS: 0.9087537707401862, test score: 0.9508483364063816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9508483364063816"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_trainVal = pd.DataFrame()\n",
    "aggregate_test = pd.DataFrame()\n",
    "\n",
    "for i in range(len(output)):\n",
    "    aggregate_trainVal[str(i)] = df.iloc[:-392,:][output[i]].mean(axis=1)\n",
    "    aggregate_trainVal = aggregate_trainVal.copy()\n",
    "    aggregate_test[str(i)] = df.iloc[-392:,:][output[i]].mean(axis=1)\n",
    "    aggregate_test = aggregate_test.copy()\n",
    "print(f'Number of aggregated features: {len(output)}\\n')\n",
    "compare_methods(aggregate_trainVal, aggregate_test, df.iloc[:-392,:], df.iloc[-392:,:], list(aggregate_trainVal.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4750956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 0.8715847717276335, test score: 0.8226923667831211\n",
      "Aggregate regression train score with FS: 0.8715847717276335, test score: 0.8226923667831211\n",
      "(392, 20)\n",
      "Full aggregate regression train score: 0.8715847717276335, test score: 0.8226923667831211\n",
      "Aggregate regression train score with FS: 0.8715847717276335, test score: 0.8226923667831211\n",
      "(392, 20)\n",
      "Full aggregate regression train score: 0.8715847717276335, test score: 0.8226923667831211\n",
      "Aggregate regression train score with FS: 0.8715847717276335, test score: 0.8226923667831211\n",
      "(392, 20)\n",
      "Full aggregate regression train score: 0.8715847717276335, test score: 0.8226923667831211\n",
      "Aggregate regression train score with FS: 0.8715847717276335, test score: 0.8226923667831211\n",
      "(392, 20)\n",
      "Full aggregate regression train score: 0.8715847717276335, test score: 0.8226923667831211\n",
      "Aggregate regression train score with FS: 0.8715847717276335, test score: 0.8226923667831211\n",
      "(392, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "r2 = []\n",
    "for curr_seed in [0,1,2,3,4]: \n",
    "    pca = PCA(n_components=0.95)\n",
    "    trainVal_pca = pd.DataFrame(pca.fit_transform(df.iloc[:-392,:]))\n",
    "    test_pca = pd.DataFrame(pca.transform(df.iloc[-392:,:]))\n",
    "    actual_r2 = compare_methods(trainVal_pca, test_pca, df.iloc[:-392,:], df.iloc[-392:,:], list(trainVal_pca.columns))\n",
    "    r2.append([curr_seed,i,actual_r2])\n",
    "    print(test_pca.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6d146bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 0.14001379626791477, test score: 0.12729891392959847\n",
      "Aggregate regression train score with FS: 0.14001379626791477, test score: 0.12729891392959847\n",
      "(392, 1)\n",
      "Full aggregate regression train score: 0.14096680259208838, test score: 0.12673698668704658\n",
      "Aggregate regression train score with FS: 0.14096680259208838, test score: 0.12673698668704658\n",
      "(392, 2)\n",
      "Full aggregate regression train score: 0.1468269126329399, test score: 0.14060981176916187\n",
      "Aggregate regression train score with FS: 0.1468269126329399, test score: 0.14060981176916187\n",
      "(392, 3)\n",
      "Full aggregate regression train score: 0.15306302163960428, test score: 0.11277999495258895\n",
      "Aggregate regression train score with FS: 0.15306302163960428, test score: 0.11277999495258895\n",
      "(392, 4)\n",
      "Full aggregate regression train score: 0.15361060378324387, test score: 0.11075153199972376\n",
      "Aggregate regression train score with FS: 0.15361060378324376, test score: 0.11075153199972376\n",
      "(392, 5)\n",
      "Full aggregate regression train score: 0.16636751087934476, test score: 0.10795845855964148\n",
      "Aggregate regression train score with FS: 0.16636751087934476, test score: 0.1079584585596417\n",
      "(392, 6)\n",
      "Full aggregate regression train score: 0.16647021674142115, test score: 0.11041762325893123\n",
      "Aggregate regression train score with FS: 0.16647021674142115, test score: 0.11041762325893123\n",
      "(392, 7)\n",
      "Full aggregate regression train score: 0.166472382427727, test score: 0.11000309288444365\n",
      "Aggregate regression train score with FS: 0.166472382427727, test score: 0.11000309288444354\n",
      "(392, 8)\n",
      "Full aggregate regression train score: 0.167814992614417, test score: 0.11135840481451098\n",
      "Aggregate regression train score with FS: 0.167814992614417, test score: 0.11135840481451098\n",
      "(392, 9)\n",
      "Full aggregate regression train score: 0.16923947856930843, test score: 0.12511167871721118\n",
      "Aggregate regression train score with FS: 0.16923947856930843, test score: 0.12511167871721096\n",
      "(392, 10)\n",
      "Full aggregate regression train score: 0.20942727368750735, test score: 0.08803348169943304\n",
      "Aggregate regression train score with FS: 0.20942727368750724, test score: 0.08803348169943326\n",
      "(392, 11)\n",
      "Full aggregate regression train score: 0.23958479059923854, test score: 0.07285060937718024\n",
      "Aggregate regression train score with FS: 0.23958479059923854, test score: 0.07285060937718024\n",
      "(392, 12)\n",
      "Full aggregate regression train score: 0.4304687772685871, test score: 0.3117233293431513\n",
      "Aggregate regression train score with FS: 0.4304687772685871, test score: 0.31172332934315095\n",
      "(392, 13)\n",
      "Full aggregate regression train score: 0.7196816224689765, test score: 0.5119556889439116\n",
      "Aggregate regression train score with FS: 0.7196816224689765, test score: 0.5119556889439123\n",
      "(392, 14)\n",
      "Full aggregate regression train score: 0.7839629572863621, test score: 0.6704521673422609\n",
      "Aggregate regression train score with FS: 0.7839629572863621, test score: 0.6704521673422604\n",
      "(392, 15)\n",
      "Full aggregate regression train score: 0.8152468978658352, test score: 0.724981075893194\n",
      "Aggregate regression train score with FS: 0.8152468978658352, test score: 0.7249810758931938\n",
      "(392, 16)\n",
      "Full aggregate regression train score: 0.8699288327806471, test score: 0.8232909857858833\n",
      "Aggregate regression train score with FS: 0.8699288327806471, test score: 0.8232909857858834\n",
      "(392, 17)\n",
      "Full aggregate regression train score: 0.8709787155869004, test score: 0.823291571158373\n",
      "Aggregate regression train score with FS: 0.8709787155869004, test score: 0.823291571158373\n",
      "(392, 18)\n",
      "Full aggregate regression train score: 0.8709449122970925, test score: 0.8227603057471371\n",
      "Aggregate regression train score with FS: 0.8709449122970925, test score: 0.8227603057471371\n",
      "(392, 19)\n",
      "Full aggregate regression train score: 0.8715815737378334, test score: 0.8226976618108193\n",
      "Aggregate regression train score with FS: 0.8715815737378334, test score: 0.822697661810819\n",
      "(392, 20)\n",
      "Full aggregate regression train score: 0.875163232016658, test score: 0.8295694031859131\n",
      "Aggregate regression train score with FS: 0.875163232016658, test score: 0.8295694031859131\n",
      "(392, 21)\n",
      "Full aggregate regression train score: 0.8809838228529655, test score: 0.8375232612747483\n",
      "Aggregate regression train score with FS: 0.8809838228529655, test score: 0.8375232612747483\n",
      "(392, 22)\n",
      "Full aggregate regression train score: 0.8811435769834814, test score: 0.8382301575803324\n",
      "Aggregate regression train score with FS: 0.8811435769834814, test score: 0.8382301575803323\n",
      "(392, 23)\n",
      "Full aggregate regression train score: 0.8820570209718592, test score: 0.8376357571680262\n",
      "Aggregate regression train score with FS: 0.8820570209718592, test score: 0.8376357571680262\n",
      "(392, 24)\n",
      "Full aggregate regression train score: 0.8820780205455903, test score: 0.8376619342527432\n",
      "Aggregate regression train score with FS: 0.8820780205455903, test score: 0.837661934252743\n",
      "(392, 25)\n",
      "Full aggregate regression train score: 0.8824758857747287, test score: 0.8394320134916462\n",
      "Aggregate regression train score with FS: 0.8824758857747287, test score: 0.8394320134916463\n",
      "(392, 26)\n",
      "Full aggregate regression train score: 0.8834190135159429, test score: 0.840958772556903\n",
      "Aggregate regression train score with FS: 0.8834190135159429, test score: 0.840958772556903\n",
      "(392, 27)\n",
      "Full aggregate regression train score: 0.8835736357385001, test score: 0.8407122261486724\n",
      "Aggregate regression train score with FS: 0.8835736357385001, test score: 0.8407122261486724\n",
      "(392, 28)\n",
      "Full aggregate regression train score: 0.8840263056290922, test score: 0.8432847874554963\n",
      "Aggregate regression train score with FS: 0.8840263056290922, test score: 0.8432847874554963\n",
      "(392, 29)\n",
      "Full aggregate regression train score: 0.8841495446400448, test score: 0.8430018492128848\n",
      "Aggregate regression train score with FS: 0.8841495446400447, test score: 0.8430018492128847\n",
      "(392, 30)\n",
      "Full aggregate regression train score: 0.884458647174029, test score: 0.8425259368690247\n",
      "Aggregate regression train score with FS: 0.884458647174029, test score: 0.8425259368690245\n",
      "(392, 31)\n",
      "Full aggregate regression train score: 0.8844357510257185, test score: 0.8424287222162903\n",
      "Aggregate regression train score with FS: 0.8844357510257185, test score: 0.8424287222162903\n",
      "(392, 32)\n",
      "Full aggregate regression train score: 0.8867630709447942, test score: 0.8412428232840508\n",
      "Aggregate regression train score with FS: 0.8867630709447942, test score: 0.8412428232840508\n",
      "(392, 33)\n",
      "Full aggregate regression train score: 0.8894422447559617, test score: 0.8420505977128783\n",
      "Aggregate regression train score with FS: 0.8894422447559617, test score: 0.8420505977128783\n",
      "(392, 34)\n",
      "Full aggregate regression train score: 0.8897116563828504, test score: 0.843316748517676\n",
      "Aggregate regression train score with FS: 0.8897116563828504, test score: 0.843316748517676\n",
      "(392, 35)\n",
      "Full aggregate regression train score: 0.8900926700687025, test score: 0.8433743562044687\n",
      "Aggregate regression train score with FS: 0.8900926700687025, test score: 0.8433743562044689\n",
      "(392, 36)\n",
      "Full aggregate regression train score: 0.8924842782549405, test score: 0.8361832164991364\n",
      "Aggregate regression train score with FS: 0.8924842782549405, test score: 0.8361832164991364\n",
      "(392, 37)\n",
      "Full aggregate regression train score: 0.8928086875681156, test score: 0.8355328699913487\n",
      "Aggregate regression train score with FS: 0.8928086875681156, test score: 0.8355328699913482\n",
      "(392, 38)\n",
      "Full aggregate regression train score: 0.8956760915859109, test score: 0.8308160757809296\n",
      "Aggregate regression train score with FS: 0.8956760915859109, test score: 0.8308160757809298\n",
      "(392, 39)\n",
      "Full aggregate regression train score: 0.8958412363407422, test score: 0.830475416913032\n",
      "Aggregate regression train score with FS: 0.8958412363407422, test score: 0.830475416913032\n",
      "(392, 40)\n",
      "Full aggregate regression train score: 0.8972656045720697, test score: 0.8365265697733658\n",
      "Aggregate regression train score with FS: 0.8972656045720697, test score: 0.8365265697733658\n",
      "(392, 41)\n",
      "Full aggregate regression train score: 0.8983604883468305, test score: 0.8364737740970453\n",
      "Aggregate regression train score with FS: 0.8983604883468305, test score: 0.8364737740970455\n",
      "(392, 42)\n",
      "Full aggregate regression train score: 0.8983757097650678, test score: 0.8337764987200215\n",
      "Aggregate regression train score with FS: 0.8983757097650678, test score: 0.8337764987200217\n",
      "(392, 43)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 0.899446362967243, test score: 0.8394777427297313\n",
      "Aggregate regression train score with FS: 0.899446362967243, test score: 0.8394777427297315\n",
      "(392, 44)\n",
      "Full aggregate regression train score: 0.8999679898088248, test score: 0.8384563676538047\n",
      "Aggregate regression train score with FS: 0.8999679898088248, test score: 0.8384563676538029\n",
      "(392, 45)\n",
      "Full aggregate regression train score: 0.9004918006764336, test score: 0.8374554607529328\n",
      "Aggregate regression train score with FS: 0.9004918006764336, test score: 0.8374554607529326\n",
      "(392, 46)\n",
      "Full aggregate regression train score: 0.9064651998476233, test score: 0.8399910751498083\n",
      "Aggregate regression train score with FS: 0.9064651998476233, test score: 0.8399910751498082\n",
      "(392, 47)\n",
      "Full aggregate regression train score: 0.9066212323675689, test score: 0.840263623089395\n",
      "Aggregate regression train score with FS: 0.9066212323675689, test score: 0.8402636230893945\n",
      "(392, 48)\n",
      "Full aggregate regression train score: 0.9077582146251448, test score: 0.848140477891402\n",
      "Aggregate regression train score with FS: 0.9077582146251448, test score: 0.8481404778914019\n",
      "(392, 49)\n",
      "Full aggregate regression train score: 0.9101242913650516, test score: 0.8413390996587451\n",
      "Aggregate regression train score with FS: 0.9101242913650516, test score: 0.8413390996587453\n",
      "(392, 50)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#for curr_seed in [0,1,2,3,4]: \n",
    "for i in range(50):\n",
    "    pca = PCA(n_components=i+1, svd_solver='randomized', random_state=curr_seed)\n",
    "    trainVal_pca = pd.DataFrame(pca.fit_transform(df.iloc[:-392,:]))\n",
    "    test_pca = pd.DataFrame(pca.transform(df.iloc[-392:,:]))\n",
    "    actual_r2 = compare_methods(trainVal_pca, test_pca, df.iloc[:-392,:], df.iloc[-392:,:], list(trainVal_pca.columns))\n",
    "    r2.append([curr_seed,i,actual_r2])\n",
    "    print(test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "005fe3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of aggregated features: 39\n",
      "\n",
      "Full aggregate regression train score: 0.9119736455213072, test score: 0.8524458782157301\n",
      "Aggregate regression train score with FS: 0.9119736455213072, test score: 0.8524458782157301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8524458782157301"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = LinCFA(df.iloc[:-392,:],'mean_std', 0, 0).compute_clusters()\n",
    "aggregate_trainVal = pd.DataFrame()\n",
    "aggregate_test = pd.DataFrame()\n",
    "\n",
    "for i in range(len(output)):\n",
    "    aggregate_trainVal[str(i)] = df.iloc[:-392,:][output[i]].mean(axis=1)\n",
    "    aggregate_trainVal = aggregate_trainVal.copy()\n",
    "    aggregate_test[str(i)] = df.iloc[-392:,:][output[i]].mean(axis=1)\n",
    "    aggregate_test = aggregate_test.copy()\n",
    "print(f'Number of aggregated features: {len(output)}\\n')\n",
    "compare_methods(aggregate_trainVal, aggregate_test, df.iloc[:-392,:], df.iloc[-392:,:], list(aggregate_trainVal.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43f789f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Number of aggregated features: 10\n",
      "\n",
      "Full aggregate regression train score: 0.9118588988755109, test score: 0.9286250571838335\n",
      "Aggregate regression train score with FS: 0.9118588988755109, test score: 0.9286250571838335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9286250571838335"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = GenLinCFA(df.iloc[:-392,:],'mean_std', 0.45, -5 , 0, 1).compute_clusters()\n",
    "aggregate_trainVal = pd.DataFrame()\n",
    "aggregate_test = pd.DataFrame()\n",
    "\n",
    "for i in range(len(output)):\n",
    "    aggregate_trainVal[str(i)] = df.iloc[:-392,:][output[i]].mean(axis=1)\n",
    "    aggregate_trainVal = aggregate_trainVal.copy()\n",
    "    aggregate_test[str(i)] = df.iloc[-392:,:][output[i]].mean(axis=1)\n",
    "    aggregate_test = aggregate_test.copy()\n",
    "print(f'Number of aggregated features: {len(output)}\\n')\n",
    "compare_methods(aggregate_trainVal, aggregate_test, df.iloc[:-392,:], df.iloc[-392:,:], list(aggregate_trainVal.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69bc4b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 2.825541806750209e-06, test score: -3.696162316923691e+18\n",
      "Aggregate regression train score with FS: 2.825541806750209e-06, test score: -3.696162316923691e+18\n",
      "(392, 1)\n",
      "Full aggregate regression train score: 0.000588451396005274, test score: -2.7196037900502523e+21\n",
      "Aggregate regression train score with FS: 0.000588451396005274, test score: -2.7196037900502523e+21\n",
      "(392, 2)\n",
      "Full aggregate regression train score: 0.0005458149407753243, test score: -2.156027655455172e+21\n",
      "Aggregate regression train score with FS: 0.0005458149407753243, test score: -2.156027655455172e+21\n",
      "(392, 3)\n",
      "Full aggregate regression train score: 0.0005975224534600088, test score: -2.3636294451857824e+21\n",
      "Aggregate regression train score with FS: 0.0005975224534600088, test score: -2.3636294451857824e+21\n",
      "(392, 4)\n",
      "Full aggregate regression train score: 0.0006211006411632747, test score: -2.7456087772675477e+21\n",
      "Aggregate regression train score with FS: 0.0006211006411632747, test score: -2.7456087772675477e+21\n",
      "(392, 5)\n",
      "Full aggregate regression train score: 0.0006477789676723189, test score: -2.737383518023281e+21\n",
      "Aggregate regression train score with FS: 0.0006477789676723189, test score: -2.737383518023281e+21\n",
      "(392, 6)\n",
      "Full aggregate regression train score: 0.0007360723270601888, test score: -3.2412926906822144e+21\n",
      "Aggregate regression train score with FS: 0.0007360723270601888, test score: -3.2412926906822144e+21\n",
      "(392, 7)\n",
      "Full aggregate regression train score: 0.001031831045247067, test score: -4.5660706966102616e+21\n",
      "Aggregate regression train score with FS: 0.001031831045247067, test score: -4.5660706966102616e+21\n",
      "(392, 8)\n",
      "Full aggregate regression train score: 0.000934491489047895, test score: -4.0707305718858577e+21\n",
      "Aggregate regression train score with FS: 0.000934491489047895, test score: -4.0707305718858577e+21\n",
      "(392, 9)\n",
      "Full aggregate regression train score: 0.0015236629654883371, test score: -5.948946415367103e+21\n",
      "Aggregate regression train score with FS: 0.0015236629654883371, test score: -5.948946415367103e+21\n",
      "(392, 10)\n",
      "Full aggregate regression train score: 0.0016775364406236282, test score: -5.088229526274367e+21\n",
      "Aggregate regression train score with FS: 0.0016775364406236282, test score: -5.088229526274367e+21\n",
      "(392, 11)\n",
      "Full aggregate regression train score: 0.0017963274795175233, test score: -5.324012971009473e+21\n",
      "Aggregate regression train score with FS: 0.0017963274795175233, test score: -5.324012971009473e+21\n",
      "(392, 12)\n",
      "Full aggregate regression train score: 0.0015377871275848998, test score: -4.678975545214524e+21\n",
      "Aggregate regression train score with FS: 0.0015377871275848998, test score: -4.678975545214524e+21\n",
      "(392, 13)\n",
      "Full aggregate regression train score: 0.002119717211810701, test score: -6.796921431050764e+21\n",
      "Aggregate regression train score with FS: 0.002119717211810701, test score: -6.796921431050764e+21\n",
      "(392, 14)\n",
      "Full aggregate regression train score: 0.0038113582467026452, test score: -1.5572769202187167e+22\n",
      "Aggregate regression train score with FS: 0.0038113582467026452, test score: -1.5572769202187167e+22\n",
      "(392, 15)\n",
      "Full aggregate regression train score: 0.003647587862021351, test score: -1.505403125945861e+22\n",
      "Aggregate regression train score with FS: 0.003647587862021351, test score: -1.505403125945861e+22\n",
      "(392, 16)\n",
      "Full aggregate regression train score: 0.003909453643678007, test score: -1.5967284216857683e+22\n",
      "Aggregate regression train score with FS: 0.003909453643678007, test score: -1.5967284216857683e+22\n",
      "(392, 17)\n",
      "Full aggregate regression train score: 0.00380979550539029, test score: -2.0110564725300274e+22\n",
      "Aggregate regression train score with FS: 0.00380979550539029, test score: -2.0110564725300274e+22\n",
      "(392, 18)\n",
      "Full aggregate regression train score: 0.004248725908891582, test score: -2.3013842995028607e+22\n",
      "Aggregate regression train score with FS: 0.004248725908891582, test score: -2.3013842995028607e+22\n",
      "(392, 19)\n",
      "Full aggregate regression train score: 0.004202310077239035, test score: -2.225689456591968e+22\n",
      "Aggregate regression train score with FS: 0.004202310077239035, test score: -2.225689456591968e+22\n",
      "(392, 20)\n",
      "Full aggregate regression train score: 0.003965839616112521, test score: -1.8875308960797507e+22\n",
      "Aggregate regression train score with FS: 0.003965839616112521, test score: -1.8875308960797507e+22\n",
      "(392, 21)\n",
      "Full aggregate regression train score: 0.005025672428015215, test score: -3.026995422778053e+22\n",
      "Aggregate regression train score with FS: 0.005025672428015215, test score: -3.026995422778053e+22\n",
      "(392, 22)\n",
      "Full aggregate regression train score: 0.006192508758601556, test score: -3.2025517469678227e+22\n",
      "Aggregate regression train score with FS: 0.006192508758601556, test score: -3.2025517469678227e+22\n",
      "(392, 23)\n",
      "Full aggregate regression train score: 0.006518813181611516, test score: -3.6377775853969363e+22\n",
      "Aggregate regression train score with FS: 0.006518813181611516, test score: -3.6377775853969363e+22\n",
      "(392, 24)\n",
      "Full aggregate regression train score: 0.007003919451807117, test score: -3.941878464332664e+22\n",
      "Aggregate regression train score with FS: 0.007003919451807117, test score: -3.941878464332664e+22\n",
      "(392, 25)\n",
      "Full aggregate regression train score: 0.007325903045051652, test score: -3.864855772816698e+22\n",
      "Aggregate regression train score with FS: 0.007325903045051652, test score: -3.864855772816698e+22\n",
      "(392, 26)\n",
      "Full aggregate regression train score: 0.0069435974515321686, test score: -3.7246481959642357e+22\n",
      "Aggregate regression train score with FS: 0.0069435974515321686, test score: -3.7246481959642357e+22\n",
      "(392, 27)\n",
      "Full aggregate regression train score: 0.007964658180618867, test score: -4.282007324695347e+22\n",
      "Aggregate regression train score with FS: 0.007964658180618867, test score: -4.282007324695347e+22\n",
      "(392, 28)\n",
      "Full aggregate regression train score: 0.007650720459101645, test score: -4.193491390343261e+22\n",
      "Aggregate regression train score with FS: 0.007650720459101645, test score: -4.193491390343261e+22\n",
      "(392, 29)\n",
      "Full aggregate regression train score: 0.00888676817103573, test score: -5.837628989751964e+22\n",
      "Aggregate regression train score with FS: 0.00888676817103573, test score: -5.837628989751964e+22\n",
      "(392, 30)\n",
      "Full aggregate regression train score: 0.008542972229602874, test score: -5.7417649879102475e+22\n",
      "Aggregate regression train score with FS: 0.008542972229602874, test score: -5.7417649879102475e+22\n",
      "(392, 31)\n",
      "Full aggregate regression train score: 0.008228523824647116, test score: -5.112222156180669e+22\n",
      "Aggregate regression train score with FS: 0.008228523824647116, test score: -5.112222156180669e+22\n",
      "(392, 32)\n",
      "Full aggregate regression train score: 0.009299432389060502, test score: -5.333113003767838e+22\n",
      "Aggregate regression train score with FS: 0.009299432389060502, test score: -5.333113003767838e+22\n",
      "(392, 33)\n",
      "Full aggregate regression train score: 0.009492819893763826, test score: -6.165999752674223e+22\n",
      "Aggregate regression train score with FS: 0.009492819893763826, test score: -6.165999752674223e+22\n",
      "(392, 34)\n",
      "Full aggregate regression train score: 0.00954402625609918, test score: -7.161261108340995e+22\n",
      "Aggregate regression train score with FS: 0.00954402625609918, test score: -7.161261108340995e+22\n",
      "(392, 35)\n",
      "Full aggregate regression train score: 0.0104123276793876, test score: -8.018179806974155e+22\n",
      "Aggregate regression train score with FS: 0.0104123276793876, test score: -8.018179806974155e+22\n",
      "(392, 36)\n",
      "Full aggregate regression train score: 0.011551496190275734, test score: -8.168824380281304e+22\n",
      "Aggregate regression train score with FS: 0.011551496190275734, test score: -8.168824380281304e+22\n",
      "(392, 37)\n",
      "Full aggregate regression train score: 0.012045909453708203, test score: -8.344619755929938e+22\n",
      "Aggregate regression train score with FS: 0.012045909453708203, test score: -8.344619755929938e+22\n",
      "(392, 38)\n",
      "Full aggregate regression train score: 0.011986800296951206, test score: -8.261598008072746e+22\n",
      "Aggregate regression train score with FS: 0.011986800296951206, test score: -8.261598008072746e+22\n",
      "(392, 39)\n",
      "Full aggregate regression train score: 0.010617636916496753, test score: -7.3647768281549495e+22\n",
      "Aggregate regression train score with FS: 0.010617636916496753, test score: -7.3647768281549495e+22\n",
      "(392, 40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 0.011712129904090207, test score: -7.376481733311914e+22\n",
      "Aggregate regression train score with FS: 0.011712129904090207, test score: -7.376481733311914e+22\n",
      "(392, 41)\n",
      "Full aggregate regression train score: 0.012606562870323912, test score: -8.486494068480598e+22\n",
      "Aggregate regression train score with FS: 0.012606562870323912, test score: -8.486494068480598e+22\n",
      "(392, 42)\n",
      "Full aggregate regression train score: 0.01149455938218158, test score: -8.22782015096347e+22\n",
      "Aggregate regression train score with FS: 0.01149455938218158, test score: -8.22782015096347e+22\n",
      "(392, 43)\n",
      "Full aggregate regression train score: 0.012362521222891054, test score: -8.964411232369138e+22\n",
      "Aggregate regression train score with FS: 0.012362521222891054, test score: -8.964411232369138e+22\n",
      "(392, 44)\n",
      "Full aggregate regression train score: 0.013519518515424545, test score: -9.386578559529935e+22\n",
      "Aggregate regression train score with FS: 0.013519518515424545, test score: -9.386578559529935e+22\n",
      "(392, 45)\n",
      "Full aggregate regression train score: 0.01354096512415326, test score: -9.542242328195556e+22\n",
      "Aggregate regression train score with FS: 0.01354096512415326, test score: -9.542242328195556e+22\n",
      "(392, 46)\n",
      "Full aggregate regression train score: 0.0135745199363706, test score: -1.069769836610896e+23\n",
      "Aggregate regression train score with FS: 0.0135745199363706, test score: -1.069769836610896e+23\n",
      "(392, 47)\n",
      "Full aggregate regression train score: 0.013684275895455067, test score: -1.0008575352707905e+23\n",
      "Aggregate regression train score with FS: 0.013684275895455067, test score: -1.0008575352707905e+23\n",
      "(392, 48)\n",
      "Full aggregate regression train score: 0.014768680283963609, test score: -1.3540206689941961e+23\n",
      "Aggregate regression train score with FS: 0.014768680283963609, test score: -1.3540206689941961e+23\n",
      "(392, 49)\n",
      "Full aggregate regression train score: 0.014716259391668984, test score: -1.3333964211367452e+23\n",
      "Aggregate regression train score with FS: 0.014716259391668984, test score: -1.3333964211367452e+23\n",
      "(392, 50)\n"
     ]
    }
   ],
   "source": [
    "from lpproj import LocalityPreservingProjection\n",
    "\n",
    "#for curr_seed in [0,1,2,3,4]: \n",
    "for i in range(50):\n",
    "    lpp = LocalityPreservingProjection(n_components=i+1)\n",
    "    trainVal_lpp = pd.DataFrame(lpp.fit_transform(df.iloc[:-392,:]))\n",
    "    test_lpp = pd.DataFrame(lpp.transform(df.iloc[-392:,:]))\n",
    "    actual_r2 = compare_methods(trainVal_lpp, test_lpp, df.iloc[:-392,:], df.iloc[-392:,:], list(trainVal_lpp.columns))\n",
    "    r2.append([curr_seed,i,actual_r2])\n",
    "    print(test_lpp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0e60aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 0.13897219342908762, test score: 0.12447743422212076\n",
      "Aggregate regression train score with FS: 0.13897219342908762, test score: 0.12447743422212076\n",
      "(392, 1)\n",
      "Full aggregate regression train score: 0.14702581749200727, test score: 0.12243605134486324\n",
      "Aggregate regression train score with FS: 0.14702581749200727, test score: 0.12243605134486324\n",
      "(392, 2)\n",
      "Full aggregate regression train score: 0.1514447866560884, test score: 0.139930612609395\n",
      "Aggregate regression train score with FS: 0.1514447866560884, test score: 0.139930612609395\n",
      "(392, 3)\n",
      "Full aggregate regression train score: 0.15155812686587533, test score: 0.1412478901056533\n",
      "Aggregate regression train score with FS: 0.15155812686587533, test score: 0.1412478901056533\n",
      "(392, 4)\n",
      "Full aggregate regression train score: 0.19727865008369483, test score: 0.10083328549653625\n",
      "Aggregate regression train score with FS: 0.19727865008369483, test score: 0.10083328549653625\n",
      "(392, 5)\n",
      "Full aggregate regression train score: 0.1992842243919205, test score: 0.09866788889108524\n",
      "Aggregate regression train score with FS: 0.1992842243919205, test score: 0.09866788889108524\n",
      "(392, 6)\n",
      "Full aggregate regression train score: 0.2068885346211008, test score: 0.1234454057570381\n",
      "Aggregate regression train score with FS: 0.2068885346211008, test score: 0.1234454057570381\n",
      "(392, 7)\n",
      "Full aggregate regression train score: 0.2089753616341814, test score: 0.12415961873138692\n",
      "Aggregate regression train score with FS: 0.2089753616341814, test score: 0.12415961873138692\n",
      "(392, 8)\n",
      "Full aggregate regression train score: 0.20954389445738386, test score: 0.11923471141149\n",
      "Aggregate regression train score with FS: 0.20954389445738386, test score: 0.11923471141149\n",
      "(392, 9)\n",
      "Full aggregate regression train score: 0.21009098509966695, test score: 0.11892082188853581\n",
      "Aggregate regression train score with FS: 0.21009098509966695, test score: 0.11892082188853581\n",
      "(392, 10)\n",
      "Full aggregate regression train score: 0.21047510979152695, test score: 0.12064027539862576\n",
      "Aggregate regression train score with FS: 0.21047510979152695, test score: 0.12064027539862576\n",
      "(392, 11)\n",
      "Full aggregate regression train score: 0.22837441773283051, test score: 0.0942678687839058\n",
      "Aggregate regression train score with FS: 0.22837441773283051, test score: 0.0942678687839058\n",
      "(392, 12)\n",
      "Full aggregate regression train score: 0.2345271043069178, test score: 0.0960387535339805\n",
      "Aggregate regression train score with FS: 0.2345271043069178, test score: 0.0960387535339805\n",
      "(392, 13)\n",
      "Full aggregate regression train score: 0.23915684248821967, test score: 0.08648887702621766\n",
      "Aggregate regression train score with FS: 0.23915684248821967, test score: 0.08648887702621766\n",
      "(392, 14)\n",
      "Full aggregate regression train score: 0.23953934082275585, test score: 0.08411326365325411\n",
      "Aggregate regression train score with FS: 0.23953934082275585, test score: 0.08411326365325411\n",
      "(392, 15)\n",
      "Full aggregate regression train score: 0.24041280998393322, test score: 0.08561572793376515\n",
      "Aggregate regression train score with FS: 0.24041280998393322, test score: 0.08561572793376515\n",
      "(392, 16)\n",
      "Full aggregate regression train score: 0.2415830253165031, test score: 0.08488826444148934\n",
      "Aggregate regression train score with FS: 0.2415830253165031, test score: 0.08488826444148934\n",
      "(392, 17)\n",
      "Full aggregate regression train score: 0.24609276842716266, test score: 0.07704910448878632\n",
      "Aggregate regression train score with FS: 0.24609276842716266, test score: 0.07704910448878632\n",
      "(392, 18)\n",
      "Full aggregate regression train score: 0.24673966609511755, test score: 0.07791123621870155\n",
      "Aggregate regression train score with FS: 0.24673966609511755, test score: 0.07791123621870155\n",
      "(392, 19)\n",
      "Full aggregate regression train score: 0.24875304449733016, test score: 0.0780887422700548\n",
      "Aggregate regression train score with FS: 0.24875304449733016, test score: 0.0780887422700548\n",
      "(392, 20)\n",
      "Full aggregate regression train score: 0.24928398240553762, test score: 0.07848199376934828\n",
      "Aggregate regression train score with FS: 0.24928398240553762, test score: 0.07848199376934828\n",
      "(392, 21)\n",
      "Full aggregate regression train score: 0.25510462356424723, test score: 0.06262434076363277\n",
      "Aggregate regression train score with FS: 0.25510462356424723, test score: 0.06262434076363277\n",
      "(392, 22)\n",
      "Full aggregate regression train score: 0.255397587757607, test score: 0.06381508037911054\n",
      "Aggregate regression train score with FS: 0.255397587757607, test score: 0.06381508037911054\n",
      "(392, 23)\n",
      "Full aggregate regression train score: 0.25547259035592507, test score: 0.06293354943074281\n",
      "Aggregate regression train score with FS: 0.25547259035592507, test score: 0.06293354943074281\n",
      "(392, 24)\n",
      "Full aggregate regression train score: 0.2555044354517054, test score: 0.06391009934770309\n",
      "Aggregate regression train score with FS: 0.2555044354517054, test score: 0.06391009934770309\n",
      "(392, 25)\n",
      "Full aggregate regression train score: 0.2556165297879116, test score: 0.06358120183501381\n",
      "Aggregate regression train score with FS: 0.2556165297879116, test score: 0.06358120183501381\n",
      "(392, 26)\n",
      "Full aggregate regression train score: 0.2556824594899927, test score: 0.06320112234897546\n",
      "Aggregate regression train score with FS: 0.2556824594899927, test score: 0.06320112234897546\n",
      "(392, 27)\n",
      "Full aggregate regression train score: 0.2598168106418406, test score: 0.048123983999666775\n",
      "Aggregate regression train score with FS: 0.2598168106418406, test score: 0.048123983999666775\n",
      "(392, 28)\n",
      "Full aggregate regression train score: 0.26352626412016367, test score: 0.046374502373008886\n",
      "Aggregate regression train score with FS: 0.26352626412016367, test score: 0.046374502373008886\n",
      "(392, 29)\n",
      "Full aggregate regression train score: 0.2649625271060553, test score: 0.04356484548930817\n",
      "Aggregate regression train score with FS: 0.2649625271060553, test score: 0.04356484548930817\n",
      "(392, 30)\n",
      "Full aggregate regression train score: 0.266063796139673, test score: 0.0471392377906108\n",
      "Aggregate regression train score with FS: 0.266063796139673, test score: 0.0471392377906108\n",
      "(392, 31)\n",
      "Full aggregate regression train score: 0.268893362089087, test score: 0.046080342232936444\n",
      "Aggregate regression train score with FS: 0.268893362089087, test score: 0.046080342232936444\n",
      "(392, 32)\n",
      "Full aggregate regression train score: 0.2738100075854172, test score: 0.03503161142567435\n",
      "Aggregate regression train score with FS: 0.2738100075854172, test score: 0.03503161142567435\n",
      "(392, 33)\n",
      "Full aggregate regression train score: 0.27385848242962874, test score: 0.03696127398957394\n",
      "Aggregate regression train score with FS: 0.27385848242962874, test score: 0.03696127398957394\n",
      "(392, 34)\n",
      "Full aggregate regression train score: 0.27504605225313794, test score: 0.03377007682114064\n",
      "Aggregate regression train score with FS: 0.27504605225313794, test score: 0.03377007682114064\n",
      "(392, 35)\n",
      "Full aggregate regression train score: 0.27597399313919646, test score: 0.04465086356358683\n",
      "Aggregate regression train score with FS: 0.27597399313919646, test score: 0.04465086356358683\n",
      "(392, 36)\n",
      "Full aggregate regression train score: 0.2776017661956379, test score: 0.04206696786239361\n",
      "Aggregate regression train score with FS: 0.2776017661956379, test score: 0.04206696786239361\n",
      "(392, 37)\n",
      "Full aggregate regression train score: 0.27851102496476643, test score: 0.03739647192691242\n",
      "Aggregate regression train score with FS: 0.27851102496476643, test score: 0.03739647192691242\n",
      "(392, 38)\n",
      "Full aggregate regression train score: 0.2787885795702365, test score: 0.03750992333569059\n",
      "Aggregate regression train score with FS: 0.2787885795702365, test score: 0.03750992333569059\n",
      "(392, 39)\n",
      "Full aggregate regression train score: 0.2829702845622162, test score: 0.01899950194968536\n",
      "Aggregate regression train score with FS: 0.2829702845622162, test score: 0.01899950194968536\n",
      "(392, 40)\n",
      "Full aggregate regression train score: 0.28689023197994157, test score: 0.029177921386242422\n",
      "Aggregate regression train score with FS: 0.28689023197994157, test score: 0.029177921386242422\n",
      "(392, 41)\n",
      "Full aggregate regression train score: 0.2896770832574994, test score: 0.014290799296947654\n",
      "Aggregate regression train score with FS: 0.2896770832574994, test score: 0.014290799296947654\n",
      "(392, 42)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 0.2931297520422035, test score: 0.015394546915972862\n",
      "Aggregate regression train score with FS: 0.2931297520422035, test score: 0.015394546915972862\n",
      "(392, 43)\n",
      "Full aggregate regression train score: 0.2950021026956827, test score: 0.010248228225258504\n",
      "Aggregate regression train score with FS: 0.2950021026956827, test score: 0.010248228225258504\n",
      "(392, 44)\n",
      "Full aggregate regression train score: 0.299179012999512, test score: 0.002330811294962265\n",
      "Aggregate regression train score with FS: 0.299179012999512, test score: 0.002330811294962265\n",
      "(392, 45)\n",
      "Full aggregate regression train score: 0.3029694479557037, test score: -0.012574060610656135\n",
      "Aggregate regression train score with FS: 0.3029694479557037, test score: -0.012574060610656135\n",
      "(392, 46)\n",
      "Full aggregate regression train score: 0.30573480777535167, test score: -0.009137604900556484\n",
      "Aggregate regression train score with FS: 0.30573480777535167, test score: -0.009137604900556484\n",
      "(392, 47)\n",
      "Full aggregate regression train score: 0.3057931665630593, test score: -0.010849604430738458\n",
      "Aggregate regression train score with FS: 0.3057931665630593, test score: -0.010849604430738458\n",
      "(392, 48)\n",
      "Full aggregate regression train score: 0.3103990103418669, test score: -0.02513855382292851\n",
      "Aggregate regression train score with FS: 0.3103990103418669, test score: -0.02513855382292851\n",
      "(392, 49)\n",
      "Full aggregate regression train score: 0.3106425779323022, test score: -0.022175462719181915\n",
      "Aggregate regression train score with FS: 0.3106425779323022, test score: -0.022175462719181915\n",
      "(392, 50)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "\n",
    "for i in range(50):\n",
    "    lda = Isomap(n_components=i+1)\n",
    "    trainVal_lda = pd.DataFrame(lda.fit_transform(df.iloc[:-392,:-1]))\n",
    "    test_lda = pd.DataFrame(lda.transform(df.iloc[-392:,:-1]))\n",
    "    actual_r2 = compare_methods(trainVal_lda, test_lda, df.iloc[:-392,:], df.iloc[-392:,:], list(trainVal_lda.columns))\n",
    "    r2.append([curr_seed,i,actual_r2])\n",
    "    print(test_lda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c02d3f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.40272966e+00,  3.47915849e-01,  2.27089776e-01, -8.75007501e-02,\n",
       "        3.96234899e-01, -5.20478026e-01, -6.75840990e-01,  5.31836531e-01,\n",
       "        2.69482601e-01,  4.36099981e-01,  4.17928788e-01,  1.30549968e+00,\n",
       "        1.86890659e+00,  1.79950127e+00,  5.16553300e-01,  2.73939536e-01,\n",
       "       -1.26309644e-01,  3.83881574e-01, -1.12432475e+00,  2.00832731e-01,\n",
       "        3.01718948e-01, -2.78975436e+00,  1.02833537e+00,  6.87989452e-01,\n",
       "        1.32760991e+00,  1.08908167e+00,  6.92910172e-01,  1.14154300e+00,\n",
       "        8.14677915e-02, -6.84698351e-01,  9.90145741e-01,  9.24474000e-01,\n",
       "        1.57601533e+00,  1.29854064e+00,  7.75564287e-01,  9.38668150e-02,\n",
       "        2.77368444e-03,  6.51316041e-01,  9.96011897e-01,  1.71512309e+00,\n",
       "        1.05141719e+00, -5.96593379e-03, -1.12471171e-01,  7.59438928e-01,\n",
       "       -7.16684520e-01, -1.67476671e+00, -1.08387536e+00, -1.30265366e+00,\n",
       "       -1.01661445e+00, -1.41076082e+00, -1.56628638e+00, -1.56314274e+00,\n",
       "       -4.24513370e-01, -6.62299754e-01, -9.87665051e-01,  6.63418528e-02,\n",
       "       -2.60330976e-01, -3.62930966e-01,  9.99671755e-01,  8.38764210e-01,\n",
       "        1.87794052e-01,  8.51907297e-01,  7.33192049e-03,  3.93448562e-01,\n",
       "        4.06988763e-01,  4.36809155e-01,  2.74641201e-01, -3.36933680e-01,\n",
       "        1.22688953e+00, -4.62836029e-02,  1.17146541e+00,  2.21919208e+00,\n",
       "        1.55996383e+00,  2.48056271e+00,  1.33844689e+00,  2.17200631e+00,\n",
       "        2.40325070e+00,  2.44049140e+00,  1.19711723e+00,  2.26672953e+00,\n",
       "        1.11319248e+00,  7.94286908e-01,  3.49442101e-01,  4.09864685e-01,\n",
       "        1.02410046e+00,  7.03430945e-01, -5.57555347e-01, -7.08420533e-01,\n",
       "        8.35478617e-01, -3.27058128e-01, -7.04410877e-01, -1.23293641e+00,\n",
       "       -7.60429540e-01,  2.43578071e-01, -2.62358427e-01, -3.96181816e-01,\n",
       "        4.17487921e-03, -5.40200391e-01, -9.78058449e-01, -1.40498995e+00,\n",
       "       -6.31221672e-01, -1.00102051e+00,  1.28286999e-01,  7.68857686e-01,\n",
       "       -5.20993012e-01, -9.87282696e-01, -1.44973795e+00, -9.05380994e-01,\n",
       "       -8.92716451e-01, -7.55412568e-01, -1.20402080e+00, -1.29383216e+00,\n",
       "       -1.44981459e+00, -3.27276718e-01, -7.35993654e-01, -7.10604369e-01,\n",
       "       -1.20990120e+00, -1.14611398e+00, -2.02044483e+00, -1.91924442e+00,\n",
       "       -1.58161156e+00, -9.83794758e-01, -8.28836158e-01, -1.75093883e+00,\n",
       "       -1.34538612e+00,  1.01644240e+00, -3.97359771e-02,  1.04277363e+00,\n",
       "        1.64974722e+00,  5.08659876e-02,  2.92308670e-01, -7.31075652e-01,\n",
       "       -7.12346558e-01, -2.72457813e-01, -1.19940470e+00, -1.04520614e-02,\n",
       "       -2.71631090e+00, -8.95755232e-01, -7.73823647e-01, -4.12247506e-02,\n",
       "        1.54858682e-02, -1.58969722e+00, -8.06382994e-01,  5.53928635e-01,\n",
       "        5.81308798e-01,  5.81320384e-01, -7.11297490e-01, -2.25040118e-01,\n",
       "       -1.20579949e-02,  1.14798098e+00,  3.49948542e-01, -2.03191914e-01,\n",
       "        1.07589133e+00,  7.26930264e-01, -9.64793154e-01, -7.30986143e-02,\n",
       "       -1.20818465e-01, -3.22684948e-03,  9.61157573e-01,  7.35361900e-01,\n",
       "        4.89817841e-01,  1.26153860e+00,  1.11733003e-01,  1.09562897e+00,\n",
       "        1.95367768e+00,  7.21737357e-01,  6.40611501e-01,  8.99949035e-02,\n",
       "       -1.09447257e+00,  6.88602891e-01,  4.03087064e-02, -9.43760356e-02,\n",
       "       -2.47467261e-01,  8.49620411e-01,  6.39842193e-01,  5.42556347e-01,\n",
       "        1.14594097e+00,  3.91539307e-01, -5.31323158e-01, -8.89904611e-01,\n",
       "       -7.81991188e-01,  2.82763744e-02, -6.63391413e-01, -6.05187166e-01,\n",
       "       -4.49254002e-01,  1.12872033e-02, -6.62042844e-01, -1.17441991e+00,\n",
       "       -1.41346676e+00, -2.51048409e-01,  7.07533164e-01, -5.43909444e-01,\n",
       "       -2.06030907e+00, -5.28449567e-01,  4.01271549e-01,  8.76853574e-01,\n",
       "        8.44927538e-01,  3.67229643e-01, -3.80919687e-01,  8.61947197e-01,\n",
       "        1.17099897e+00, -7.23765256e-01,  4.76728221e-01,  1.05478990e+00,\n",
       "       -4.13319735e-01, -5.10293909e-01,  1.89511514e-01,  7.77110022e-01,\n",
       "        9.19352285e-02, -2.61663946e-01,  4.45576607e-01,  6.80558983e-01,\n",
       "        1.65822055e+00,  1.54835191e+00,  1.69561698e+00,  8.20170530e-01,\n",
       "        1.15442154e+00,  1.21522370e+00,  1.66524885e+00,  8.32237751e-01,\n",
       "        4.28127081e-01,  6.63976830e-01,  1.05528735e+00,  1.46641733e+00,\n",
       "        9.74436592e-01,  8.60268576e-03, -3.11633010e-01, -7.73044565e-01,\n",
       "       -2.19594106e+00, -1.69646992e+00, -1.49385548e+00, -1.70733492e+00,\n",
       "       -1.83861257e+00, -1.42450634e+00, -8.20700981e-01, -6.79032144e-01,\n",
       "       -7.49378957e-01, -2.98631940e-01, -5.70491182e-02, -7.49420837e-01,\n",
       "        2.32514413e-01, -2.86523486e-01, -3.32769192e-01, -8.37871018e-02,\n",
       "        4.67777197e-01, -3.59875874e-01,  6.93221066e-01,  9.58569503e-01,\n",
       "        2.20241730e-02, -8.60599075e-01, -1.11271704e+00, -6.23939369e-01,\n",
       "       -9.41352091e-01, -1.62521165e+00, -5.43642241e-01,  5.44105319e-01,\n",
       "        2.11377553e+00,  1.88087439e+00,  1.10786177e+00,  2.33611449e-03,\n",
       "        1.27167734e+00,  1.27614405e+00,  1.35401072e+00,  7.77982573e-01,\n",
       "        2.69450560e-01,  1.25785018e-01,  1.00812818e+00, -1.86151154e-01,\n",
       "       -3.45986135e-01, -9.87564268e-01, -5.10391262e-01, -1.58681406e-01,\n",
       "        4.32565115e-01, -1.02083603e+00, -5.30826232e-01, -7.67002087e-01,\n",
       "       -7.35023491e-01,  5.54138099e-01,  1.82081564e-01,  1.88408851e-01,\n",
       "        6.78650958e-01,  2.90631276e-01,  1.30346491e-01,  4.00868739e-01,\n",
       "        2.29481019e+00,  1.78768494e+00,  1.12211029e-01, -3.46409723e-01,\n",
       "       -1.00431983e+00, -6.08204263e-01, -6.27021518e-01, -8.23219857e-01,\n",
       "        1.09970360e-01,  1.03400048e+00,  1.27273243e+00,  5.00699416e-01,\n",
       "        1.18079549e+00,  4.11244325e-01, -1.26325275e+00, -1.27790190e+00,\n",
       "       -1.04227184e+00, -5.28993552e-01, -1.02540934e+00, -3.26085894e-01,\n",
       "        8.61087592e-01, -8.64264306e-01, -5.44340217e-01, -7.45075754e-01,\n",
       "       -4.63937775e-01, -3.25994108e-01,  2.43561112e-01,  2.27604503e-01,\n",
       "        7.94459076e-02, -3.87007929e-01,  1.83737986e-01, -1.14886660e+00,\n",
       "       -1.41733712e+00, -6.57541505e-01, -4.26103445e-01, -8.99239026e-01,\n",
       "       -1.94950620e+00, -6.70545229e-01, -1.34752322e+00, -9.47410105e-01,\n",
       "       -4.69333996e-01, -6.62018505e-01, -1.03618017e+00, -2.99888788e-01,\n",
       "       -6.11846721e-02,  9.90482981e-01,  4.18319235e-01,  4.75322689e-01,\n",
       "        1.04169718e+00,  1.06380410e+00,  3.70740365e-01, -2.58884341e-01,\n",
       "        1.27575334e+00,  1.65368238e+00,  1.86889449e+00,  1.99175397e+00,\n",
       "        5.49881760e-01,  5.72459981e-01,  7.59351543e-01,  1.26477364e+00,\n",
       "        7.96005794e-01,  2.80398094e-01,  3.79700969e-01,  3.75097811e-01,\n",
       "       -2.97242784e-01, -7.33133396e-01, -1.35107880e+00,  1.88537339e-01,\n",
       "       -7.72640731e-02, -4.20816227e-01, -2.10523410e+00, -2.18178185e+00,\n",
       "       -1.38189641e+00, -1.33455161e+00, -1.35351372e+00, -1.02475305e+00,\n",
       "       -4.16728250e-01, -5.70849642e-01, -1.52754047e+00, -1.35150265e+00,\n",
       "       -1.77345252e+00, -2.61881549e+00, -2.37596064e+00, -2.34900037e+00,\n",
       "       -1.76500709e+00, -1.64003822e+00, -7.20880920e-01, -8.32617901e-01,\n",
       "       -1.55643044e+00, -1.43926617e+00, -1.23285181e+00, -1.27709149e+00,\n",
       "        1.36235626e-01, -3.96746838e-01, -6.67742322e-01,  1.09501171e+00,\n",
       "       -3.67413599e-01, -5.04741431e-01, -1.14590815e+00, -1.01956824e+00,\n",
       "       -3.72359563e-01, -1.03901324e+00,  4.91930540e-01,  6.79045159e-01,\n",
       "        1.17516501e+00,  4.19846911e-01, -5.00029140e-01, -6.16195287e-01,\n",
       "       -2.89811410e-01, -1.26040920e+00, -6.86000704e-01, -3.80192583e-01,\n",
       "       -1.23338414e+00,  2.53909901e-01, -2.47188343e-01,  9.58126305e-03,\n",
       "        6.88271671e-01,  1.42560208e+00,  6.70184756e-01,  1.21949033e+00,\n",
       "        9.61385874e-01, -2.45011638e-02,  3.54456602e-02,  2.27612788e-01,\n",
       "        7.94042296e-01,  4.98349484e-01, -2.25220621e+00, -2.25220621e+00,\n",
       "       -2.27194568e-01,  2.39791603e-01,  8.67740726e-01,  1.20347818e+00,\n",
       "        1.84263264e-01,  3.98515700e-01, -1.18011156e-01, -1.30596082e-01,\n",
       "        1.46436088e+00,  1.16418161e+00, -2.04227971e-01,  1.17811893e+00,\n",
       "        7.75439748e-01,  5.57587781e-01,  3.88308075e-02,  7.17867841e-01,\n",
       "        1.48542767e+00, -1.25923664e-01, -6.14699652e-01, -5.20466440e-01,\n",
       "        2.94227505e-01,  2.10003454e+00,  6.77814267e-01,  6.96351180e-01,\n",
       "        1.14483480e-01,  1.09494470e-01,  8.28494715e-01,  1.54784353e+00,\n",
       "        2.14159682e+00,  7.60536089e-01,  1.34398966e+00,  1.60296349e+00,\n",
       "        1.31842353e+00,  1.10540244e+00,  1.20664448e+00,  1.47456998e+00,\n",
       "        1.41351441e+00,  1.18519319e+00,  7.01197073e-01,  5.40346296e-01,\n",
       "       -2.42495664e-01,  7.34599907e-01, -1.71178494e-01, -2.53545405e-01,\n",
       "       -1.80669372e+00, -1.87574860e+00, -1.92703452e+00,  1.25929882e-01,\n",
       "        3.56472919e-02, -9.85268320e-01, -1.24501314e+00, -6.24310458e-03,\n",
       "       -1.76966388e-03, -3.87147939e-01,  4.14866381e-01, -6.53894398e-01,\n",
       "       -6.77025989e-01, -1.31356307e+00, -3.24823155e-01,  2.22868650e-01,\n",
       "       -2.78543854e-01, -1.10796203e+00, -1.38695947e+00, -1.05375514e+00,\n",
       "        1.20740272e+00,  1.43198459e+00,  1.14816675e+00,  6.87212700e-01,\n",
       "        1.17460607e+00,  1.04667512e+00,  1.83609208e+00,  1.17458050e+00,\n",
       "        9.60803957e-01, -5.70404239e-01, -1.33658488e+00, -6.46051086e-01,\n",
       "       -6.06365110e-01, -7.10520351e-01, -1.25297821e+00, -1.75545713e+00,\n",
       "       -1.06984282e+00,  1.85662193e-01,  2.18838087e-01,  1.37619020e-01,\n",
       "       -8.93690961e-02, -4.51583156e-01, -9.50622619e-01, -1.25126250e+00,\n",
       "       -5.35392947e-01, -1.75857127e-01, -1.15367838e+00, -1.06635430e+00,\n",
       "       -9.19312806e-01, -5.95386829e-01, -8.67434811e-01,  1.09900421e+00,\n",
       "        1.07203819e+00, -7.21653593e-01, -1.52365594e+00, -7.52417285e-01,\n",
       "       -9.66101203e-01, -1.36144300e+00, -1.20283159e+00,  1.32218948e+00,\n",
       "        1.60373338e+00,  6.11381310e-01,  4.59770185e-01, -1.80129518e-01,\n",
       "        1.19215936e+00,  7.22711533e-01,  8.83350840e-01,  1.37840589e+00,\n",
       "       -6.13400536e-01, -4.86376828e-01, -6.17440937e-01, -5.57167231e-01,\n",
       "       -5.36909554e-01, -1.06230283e+00, -1.13116993e+00, -1.82511419e+00,\n",
       "       -2.19922283e+00, -1.97043790e+00, -5.89955525e-01,  8.34971527e-01,\n",
       "        5.54953947e-01,  1.03385315e+00,  8.95275269e-01,  7.16930302e-01,\n",
       "        5.73866549e-01,  1.03689880e+00,  7.29157922e-01, -8.20509329e-02,\n",
       "        3.36555277e-01,  1.93632279e+00,  1.54407861e+00,  8.70839058e-01,\n",
       "       -1.87595782e-01, -9.06750406e-01,  3.66065799e-02,  7.46931936e-01,\n",
       "        1.46209567e-01, -3.67614000e-01,  1.20540038e+00,  1.00585062e+00,\n",
       "        1.48821911e-01,  2.43622476e-01,  1.16907495e+00,  8.39700972e-01,\n",
       "        1.03568214e+00, -1.23890387e-01, -1.01788359e+00,  6.51201859e-01,\n",
       "        3.54581411e-01,  3.86465049e-01,  1.79422357e+00,  1.74251833e+00,\n",
       "        1.60397384e-01, -9.00017914e-01, -6.99376169e-01,  6.40648396e-01,\n",
       "       -4.22577835e-01,  3.47830730e-01, -4.21170944e-01, -1.09956366e+00,\n",
       "       -2.76327329e-01,  8.87770868e-02,  1.02103650e+00,  3.69590255e-01,\n",
       "       -5.04148846e-02,  5.16472712e-01, -1.07536695e+00,  1.10323168e+00,\n",
       "        1.99986461e+00,  1.08118261e-01,  7.16162872e-01,  4.06051224e-01,\n",
       "        6.24301016e-01])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:-392,-1].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
